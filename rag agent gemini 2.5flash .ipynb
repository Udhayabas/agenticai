{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4bf45f9-358f-41a2-83c0-85e308d728f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries if you haven't already\n",
    "# !pip install pypdf\n",
    "# !pip install langchain\n",
    "# !pip install langchain-google-genai\n",
    "# !pip install chromadb\n",
    "# !pip install -U langchain-community\n",
    "# !pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib\n",
    "\n",
    "import os\n",
    "import getpass\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1466bf0-ea2f-4b84-a5b5-60572437525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain_google_genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6f0a608-9bf3-4e35-8b16-42be8d7bb21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "you api key ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "API key set successfully!\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Set up the API Key ---\n",
    "# For security, use getpass to hide your API key input.\n",
    "# Or, you can set it as an environment variable.\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"you api key\")\n",
    "    print(\"\\nAPI key set successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dee14b9f-434f-4244-975f-d5acd6b2014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2afbfd92-9d3c-4eaf-a48f-bb13deff3f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 1 pages from BELT_STOCK_STRUCTURED.pdf\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Load the Document ---\n",
    "# Define the path to your PDF file.\n",
    "# The file 'BELT STOCK.pdf' should be in the same directory as this notebook.\n",
    "file_path = \"BELT_STOCK_STRUCTURED.pdf\"\n",
    "try:\n",
    "    loader = PyMuPDFLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    print(f\"\\nLoaded {len(documents)} pages from {file_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nError: The file '{file_path}' was not found. Please ensure it is in the same directory.\")\n",
    "    # Exit gracefully if the file is not found\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bae465ca-8d41-48b1-b3af-0e06cbdc5b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 pages into 1 chunks.\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Split Documents into Chunks ---\n",
    "# We split the documents into smaller, manageable chunks.\n",
    "# This helps the model focus on relevant information without being overwhelmed.\n",
    "# The chunk size and overlap can be tuned for better performance.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "print(f\"Split {len(documents)} pages into {len(docs)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5048920a-a8db-4b44-b8f1-4586320dbe45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Initialize Embedding Model and Vector Store ---\n",
    "# An embedding model converts text into numerical vectors.\n",
    "# We'll use Google's embedding model for this.\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "# We'll use Chroma as our vector store to store the document chunks and their embeddings.\n",
    "# This allows us to quickly search for relevant chunks later.\n",
    "vectorstore = Chroma.from_documents(docs, embeddings)\n",
    "print(\"Vector store created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "078f10af-84c7-45b6-b219-fb5f4fedbccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever created.\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Create the Retriever ---\n",
    "# The retriever is a key component of RAG. It's responsible for fetching\n",
    "# the most relevant document chunks based on a user's query.\n",
    "retriever = vectorstore.as_retriever()\n",
    "print(\"Retriever created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf2626b3-8796-4519-98fc-09ac7ab1c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Set up the RAG Chain ---\n",
    "# First, define the prompt template that will guide the LLM's response.\n",
    "# The prompt tells the model to use the provided context to answer the question.\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the user's question based only on the provided context.\n",
    "Answer strictly from the BELT STOCK table.provided context of each row and each column have precise stock details \n",
    "If you do not have enough information in the context, please state that you cannot answer.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{input}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efa2da5d-e679-4358-b89c-43c0d385aa0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG chain setup complete.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM with the gemini-2.5-flash model.\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n",
    "# Create a 'stuff' documents chain. This chain takes the retrieved documents\n",
    "# and 'stuffs' them into the prompt's context.\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# Create the final retrieval chain. This chain combines the retriever and the document chain.\n",
    "# When a user asks a question, this chain will:\n",
    "# 1. Retrieve relevant documents using the retriever.\n",
    "# 2. Pass those documents to the document chain for generation.\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "print(\"RAG chain setup complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "600d6915-54c2-4d42-8d56-4e52f2a91bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing the RAG Agent with a list of questions ---\n",
      "--------------------------------------------------\n",
      "Question: What is the belt drum details of BELT STRENGTH EP800/4 AND BELT WIDTH 2400MM?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "For BELT STRENGTH EP800/4 and BELT WIDTH 2400MM, the belt drum details are:\n",
      "*   Drum Length: 250m, No. of Drums: 1\n",
      "*   Drum Length: 187m, No. of Drums: 1\n",
      "--------------------------------------------------\n",
      "Question: What is the total stock belt in meters for the ST 2000, 2000 mm belt?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "The total stock belt in meters for the ST2000, 2000 mm belt is 3440 meters.\n",
      "--------------------------------------------------\n",
      "Question: What are the belt details of no of drum,drum length of  ST1400, 2000mm width\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "For ST1400 with 2000mm width, the Drum Length is 500m. The number of drums is not provided in the context.\n",
      "--------------------------------------------------\n",
      "Question: What are the belt details of no of drum,drum length of  ST2000, 2000mm width?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "For ST2000, 2000mm width, the belt details are:\n",
      "\n",
      "*   Drum Length: 250m, No. of Drums: 6\n",
      "*   Drum Length: 300m, No. of Drums: 3\n",
      "*   Drum Length: 190m, No. of Drums: 1\n",
      "*   Drum Length: 200m, No. of Drums: 3\n",
      "*   Drum Length: 250m, No. of Drums: 1\n"
     ]
    }
   ],
   "source": [
    "#--- 7. Test the Agent with multiple questions ---\n",
    "print(\"\\n--- Testing the RAG Agent with a list of questions ---\")\n",
    "\n",
    "# Define a list of questions you want to ask.\n",
    "questions = [\n",
    "    \"What is the belt drum details of BELT STRENGTH EP800/4 AND BELT WIDTH 2400MM?\",\n",
    "    \"What is the total stock belt in meters for the ST 2000, 2000 mm belt?\",\n",
    "    \"What are the belt details of no of drum,drum length of  ST1400, 2000mm width\",\n",
    "    \"What are the belt details of no of drum,drum length of  ST2000, 2000mm width?\"\n",
    "]\n",
    "\n",
    "# Loop through the questions and get the answers.\n",
    "\n",
    "for question in questions:\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Question: {question}\")\n",
    "    response = retrieval_chain.invoke({\"input\": question})\n",
    "    print(\"Answer:\")\n",
    "    print(response[\"answer\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c12b348-e9bf-466b-a542-c6b042875ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
